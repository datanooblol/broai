{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ae67163-f7d3-4682-94b0-cd6fa366844e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.12 (main, Apr  9 2025, 04:04:00) [Clang 20.1.0 ]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version) # broai supports python3.11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed11cdd5-a158-4627-b88c-4e51466dc87c",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13b8f02f-418d-4043-a81e-858080926275",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d2359ff-1d69-4d0b-b89b-3398913550da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda9e248-121f-4d65-b570-510325cf7b0b",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75032c1-5306-4253-842f-a4fd39829887",
   "metadata": {},
   "source": [
    "## pdf_to_markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a34672a7-4c5c-4627-bb22-4fa1c5e768af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/broai/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/tmp/ipykernel_16058/2694963727.py:3: UserWarning: [EXPERIMENT] You're using an experimental module, which is subject to change in future.: pdf_to_markdown\n",
      "  markdown_text, images = pdf_to_markdown(\"./docs/test1/storm.pdf\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded layout model s3://layout/2025_02_18 on device cuda with dtype torch.float16\n",
      "Loaded texify model s3://texify/2025_02_18 on device cuda with dtype torch.float16\n",
      "Loaded recognition model s3://text_recognition/2025_02_18 on device cuda with dtype torch.float16\n",
      "Loaded table recognition model s3://table_recognition/2025_02_18 on device cuda with dtype torch.float16\n",
      "Loaded detection model s3://text_detection/2025_02_28 on device cuda with dtype torch.float16\n",
      "Loaded detection model s3://inline_math_detection/2025_02_24 on device cuda with dtype torch.float16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recognizing layout: 100%|██████████| 5/5 [00:04<00:00,  1.19it/s]\n",
      "Running OCR Error Detection: 100%|██████████| 7/7 [00:00<00:00, 61.51it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Texify inference: 100%|██████████| 1/1 [00:01<00:00,  1.44s/it]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Recognizing tables: 100%|██████████| 2/2 [00:01<00:00,  1.46it/s]\n"
     ]
    }
   ],
   "source": [
    "from broai.experiments.pdf_to_markdown import pdf_to_markdown\n",
    "\n",
    "markdown_text, images = pdf_to_markdown(\"./docs/test1/storm.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cecae8f5-7f93-47d2-ae2c-c0a004da6618",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./docs/test1/storm.md\", \"w\") as f:\n",
    "    f.write(markdown_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cae2991-b027-4bf2-9789-888ae940c6d3",
   "metadata": {},
   "source": [
    "## chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb92fa35-16c9-4d4c-9657-806e83d75061",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./docs/test1/storm.md\", \"r\") as f:\n",
    "    markdown_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b35e5a48-7de5-411d-8c49-2707562bc233",
   "metadata": {},
   "outputs": [],
   "source": [
    "from broai.experiments.chunk import split_markdown, consolidate_markdown, get_markdown_sections, split_overlap, chunk_chunks\n",
    "from broai.interface import Context, Contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d92f3b57-ec86-49ad-b037-5455266bcedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markdown headings: max(4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16058/3854812085.py:1: UserWarning: [EXPERIMENT] You're using an experimental module, which is subject to change in future.: split_markdown\n",
      "  chunks = split_markdown(markdown_text)\n"
     ]
    }
   ],
   "source": [
    "chunks = split_markdown(markdown_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8e6aa14-e46b-4074-ac7e-42afe5d8548e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef007eb4-3903-4e9c-8b62-88e280b0e7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16058/169284658.py:1: UserWarning: [EXPERIMENT] You're using an experimental module, which is subject to change in future.: consolidate_markdown\n",
      "  consolidated_chunks = consolidate_markdown(chunks)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consolidated_chunks = consolidate_markdown(chunks)\n",
    "len(consolidated_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4da9c06-c3ef-4b78-a76e-00f8659b60b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16058/2669657907.py:1: UserWarning: [EXPERIMENT] You're using an experimental module, which is subject to change in future.: get_markdown_sections\n",
      "  sections = get_markdown_sections(consolidated_chunks)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sections = get_markdown_sections(consolidated_chunks)\n",
    "len(sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b840acec-1a27-4d39-8031-b30e5f24b830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contexts = Contexts()\n",
    "source = \".docs/test1/storm.md\"\n",
    "for section, chunk in zip(sections, consolidated_chunks):\n",
    "    contexts.add_context(Context(context=chunk, metadata={\"section\": section, \"source\": source, \"type\": \"document\"}))\n",
    "len(contexts.contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f86b25e-3be5-4f0f-800b-9661b8053e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16058/1421024119.py:1: UserWarning: [EXPERIMENT] You're using an experimental module, which is subject to change in future.: split_overlap\n",
      "  new_contexts = split_overlap(contexts.contexts)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_contexts = split_overlap(contexts.contexts)\n",
    "new_contexts = Contexts(contexts=new_contexts)\n",
    "len(new_contexts.contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ade5498-fe67-4ddd-87fd-9c73e155d493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Context(id='b0c304aa-1765-42bf-bb0e-31f7173299a1', context='# arXiv:2402.14207v2 [cs.CL] 8 Apr 2024\\n\\nAssisting in Writing Wikipedia-like Articles From Scratch with Large Language Models\\n\\nYijia Shao Yucheng Jiang Theodore A. Kanell Peter Xu Omar Khattab Monica S. Lam\\n\\nStanford University\\n\\n{shaoyj, yuchengj, tkanell, peterxu, okhattab}@stanford.edu lam@cs.stanford.edu\\n', metadata={'section': '# arXiv:2402.14207v2 [cs.CL] 8 Apr 2024', 'source': '.docs/test1/storm.md', 'type': 'document', 'sequence': 0}, type='document', created_at='2025-04-29 22:28:50.077994'),\n",
       " Context(id='f9aae27f-15fd-4ed1-9a2f-70b8e3345009', context=\"Abstract\\n\\nWe study how to apply large language models to write grounded and organized long-form articles from scratch, with comparable breadth and depth to Wikipedia pages. This underexplored problem poses new challenges at the *pre-writing* stage, including how to research the topic and prepare an outline prior to writing. We propose STORM, a writing system for the Synthesis of Topic Outlines through Retrieval and Multi-perspective Question Asking. STORM models the pre-writing stage by (1) discovering diverse perspectives in researching the given topic, (2) simulating conversations where writers carrying different perspectives pose questions to a topic expert grounded on trusted Internet sources, (3) curating the collected information to create an outline.\\n\\nFor evaluation, we curate FreshWiki, a dataset of recent high-quality Wikipedia articles, and formulate outline assessments to evaluate the pre-writing stage. We further gather feedback from experienced Wikipedia editors. Compared to articles generated by an outlinedriven retrieval-augmented baseline, more of STORM's articles are deemed to be organized (by a 25% absolute increase) and broad in coverage (by 10%). The expert feedback also helps identify new challenges for generating grounded long articles, such as source bias transfer and over-association of unrelated facts.\\n\", metadata={'section': 'Abstract', 'source': '.docs/test1/storm.md', 'type': 'document', 'sequence': 1}, type='document', created_at='2025-04-29 22:28:50.078062'),\n",
       " Context(id='d8b9ba10-97e4-4e15-8180-a91b3b7be064', context='1 Introduction\\n\\nLarge language models (LLMs) have demonstrated impressive writing capabilities [\\\\(Yang et al.,](#page-12-0) [2023;](#page-12-0) [Pavlik,](#page-10-0) [2023;](#page-10-0) [Wenzlaff and Spaeth,](#page-11-0) [2022;](#page-11-0) [Fitria,](#page-9-0) [2023\\\\)](#page-9-0), but it is unclear how we can use them to write grounded, long-form articles, like full-length Wikipedia pages. Such expository writing, which seeks to inform the reader on a topic in an organized manner [\\\\(Weaver III and Kintsch,](#page-11-1) [1991;](#page-11-1) [Balepur et al.,](#page-9-1) [2023\\\\)](#page-9-1), requires thorough research and planning in the *pre-writing* stage [\\\\(Rohman,](#page-11-2)\\n\\n<span id=\"page-0-0\"></span>![](_page_0_Picture_10.jpeg)\\n\\nFigure 1: We explore writing Wikipedia-like articles from scratch, which demands a pre-writing stage before producing the article. In this stage, simpler approaches like Direct Prompting have limited planning capacity. In contrast, STORM researches the topic via perspectiveguided question asking in simulated conversations.\\n\\n[1965\\\\)](#page-11-2), even before the actual writing process can start. However, prior work on generating Wikipedia articles [\\\\(Banerjee and Mitra,](#page-9-2) [2015;](#page-9-2) [Minguillón](#page-10-1) [et al.,](#page-10-1) [2017;](#page-10-1) [Liu et al.,](#page-10-2) [2018;](#page-10-2) [Fan and Gardent,](#page-9-3) [2022\\\\)](#page-9-3) has generally bypassed the pre-writing stage: for instance, [Liu et al.](#page-10-2) [\\\\(2018\\\\)](#page-10-2) presume reference documents are provided in advance, while [Fan and](#page-9-3) [Gardent](#page-9-3) [\\\\(2022\\\\)](#page-9-3) assume an article outline is available and focus on expanding each section. These assumptions do not hold in general, as collecting references and crafting outlines demand advanced information literacy skills [\\\\(Doyle,](#page-9-4) [1994\\\\)](#page-9-4) to identify, evaluate, and organize external sources - a task that is challenging even for experienced writers. Automating this process can facilitate individuals in initiating in-depth learning about a topic and greatly reduce the expensive expert hours necessary for their expository writing.\\n\\nWe explore these challenges by focusing on how to generate Wikipedia-like articles *from scratch*. We decompose this problem into two tasks. The first is to conduct research to generate an outline, *i.e.*, a list of multi-level sections, and collect a set of reference documents. The second uses the outline and the references to produce the full-length article. Such a task decomposition mirrors the human writing process which usually includes phases of pre-writing, drafting, and revising [\\\\(Rohman,](#page-11-2) [1965;](#page-11-2) [Munoz-Luna,](#page-10-3) [2015\\\\)](#page-10-3).\\n\\nAs pre-trained language models inherently possess a wealth of knowledge, a direct approach is to rely on their parametric knowledge for generating outlines or even entire articles (*Direct Gen*). However, this approach is limited by a lack of details and hallucinations [\\\\(Xu et al.,](#page-11-3) [2023\\\\)](#page-11-3), particularly in addressing long-tail topics [\\\\(Kandpal et al.,](#page-10-4) [2023\\\\)](#page-10-4). This underscores the importance of leveraging external sources, and current strategies often involve retrieval-augmented generation (*RAG*), which circles back to the problem of researching the topic in the pre-writing stage, as much information cannot be surfaced through simple topic searches.\\n\\nHuman learning theories [\\\\(Tawfik et al.,](#page-11-4) [2020;](#page-11-4) [Booth et al.,](#page-9-5) [2003\\\\)](#page-9-5) highlight *asking effective questions* in information acquisition. Although instruction-tuned models [\\\\(Ouyang et al.,](#page-10-5) [2022\\\\)](#page-10-5) can be prompted directly to generate questions, we find that they typically produce basic \"What\", \"When\", and \"Where\" questions (Figure [1](#page-0-0) (A)) which often only address surface-level facts about the topic. To endow LLMs with the capacity to conduct better research, we propose the STORM paradigm for the Synthesis of Topic Outlines through Retrieval and Multi-perspective Question Asking.\\n\\nThe', metadata={'section': '1 Introduction', 'source': '.docs/test1/storm.md', 'type': 'document', 'sequence': 2}, type='document', created_at='2025-04-29 22:28:50.113771')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_contexts.contexts[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f9e613d-dc5b-49a0-86e5-683d73d0e2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] | tokens: 35 | chars: 309\n",
      "[1] | tokens: 189 | chars: 1349\n",
      "[2] | tokens: 500 | chars: 4170\n",
      "[3] | tokens: 462 | chars: 3550\n",
      "[4] | tokens: 500 | chars: 2030\n",
      "[5] | tokens: 211 | chars: 1257\n",
      "[6] | tokens: 162 | chars: 1096\n",
      "[7] | tokens: 238 | chars: 1830\n",
      "[8] | tokens: 196 | chars: 2327\n",
      "[9] | tokens: 256 | chars: 1831\n",
      "[10] | tokens: 226 | chars: 1627\n",
      "[11] | tokens: 114 | chars: 759\n",
      "[12] | tokens: 150 | chars: 1002\n",
      "[13] | tokens: 57 | chars: 422\n",
      "[14] | tokens: 166 | chars: 1305\n",
      "[15] | tokens: 105 | chars: 681\n",
      "[16] | tokens: 500 | chars: 1605\n",
      "[17] | tokens: 500 | chars: 1131\n",
      "[18] | tokens: 500 | chars: 868\n",
      "[19] | tokens: 480 | chars: 1431\n",
      "[20] | tokens: 500 | chars: 3018\n",
      "[21] | tokens: 320 | chars: 924\n",
      "[22] | tokens: 196 | chars: 1381\n",
      "[23] | tokens: 500 | chars: 2242\n",
      "[24] | tokens: 500 | chars: 3699\n",
      "[25] | tokens: 260 | chars: 1890\n",
      "[26] | tokens: 441 | chars: 3970\n",
      "[27] | tokens: 88 | chars: 637\n",
      "[28] | tokens: 159 | chars: 1194\n",
      "[29] | tokens: 62 | chars: 413\n",
      "[30] | tokens: 230 | chars: 1487\n",
      "[31] | tokens: 500 | chars: 4696\n",
      "[32] | tokens: 500 | chars: 4683\n",
      "[33] | tokens: 500 | chars: 4837\n",
      "[34] | tokens: 500 | chars: 5164\n",
      "[35] | tokens: 500 | chars: 5514\n",
      "[36] | tokens: 500 | chars: 5094\n",
      "[37] | tokens: 281 | chars: 2320\n",
      "[38] | tokens: 191 | chars: 1398\n",
      "[39] | tokens: 87 | chars: 724\n",
      "[40] | tokens: 500 | chars: 3178\n",
      "[41] | tokens: 500 | chars: 2304\n",
      "[42] | tokens: 500 | chars: 2312\n",
      "[43] | tokens: 299 | chars: 1590\n",
      "[44] | tokens: 124 | chars: 883\n",
      "[45] | tokens: 20 | chars: 232\n",
      "[46] | tokens: 500 | chars: 2032\n",
      "[47] | tokens: 500 | chars: 871\n",
      "[48] | tokens: 500 | chars: 986\n",
      "[49] | tokens: 500 | chars: 755\n",
      "[50] | tokens: 500 | chars: 864\n",
      "[51] | tokens: 500 | chars: 882\n",
      "[52] | tokens: 500 | chars: 1274\n",
      "[53] | tokens: 500 | chars: 1152\n",
      "[54] | tokens: 500 | chars: 1276\n",
      "[55] | tokens: 500 | chars: 2068\n",
      "[56] | tokens: 314 | chars: 1752\n",
      "[57] | tokens: 250 | chars: 1737\n",
      "[58] | tokens: 181 | chars: 1720\n",
      "[59] | tokens: 75 | chars: 613\n",
      "[60] | tokens: 77 | chars: 594\n",
      "[61] | tokens: 99 | chars: 685\n",
      "[62] | tokens: 121 | chars: 896\n",
      "[63] | tokens: 500 | chars: 1743\n",
      "[64] | tokens: 500 | chars: 1425\n",
      "[65] | tokens: 500 | chars: 1261\n",
      "[66] | tokens: 500 | chars: 759\n",
      "[67] | tokens: 500 | chars: 942\n",
      "[68] | tokens: 500 | chars: 1206\n",
      "[69] | tokens: 500 | chars: 826\n",
      "[70] | tokens: 500 | chars: 606\n",
      "[71] | tokens: 412 | chars: 795\n",
      "[72] | tokens: 291 | chars: 1933\n",
      "[73] | tokens: 208 | chars: 1347\n",
      "[74] | tokens: 300 | chars: 1821\n",
      "[75] | tokens: 236 | chars: 1519\n",
      "[76] | tokens: 147 | chars: 952\n",
      "[77] | tokens: 197 | chars: 1297\n",
      "[78] | tokens: 48 | chars: 319\n",
      "[79] | tokens: 93 | chars: 601\n",
      "[80] | tokens: 83 | chars: 505\n",
      "[81] | tokens: 62 | chars: 382\n",
      "[82] | tokens: 90 | chars: 631\n",
      "[83] | tokens: 190 | chars: 1229\n",
      "[84] | tokens: 219 | chars: 1497\n"
     ]
    }
   ],
   "source": [
    "chunk_chunks([c.context for c in new_contexts.contexts])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0f7b86-1837-4a5b-aeda-bf24fbb9f2b5",
   "metadata": {},
   "source": [
    "## Enmedding: BAAI/bge-m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0d51143-5bcc-4414-b85a-c8e63d8d1ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from broai.experiments.huggingface_embedding import BAAIEmbedding, EmbeddingDimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "155469bb-f92d-426d-9b95-8f1436ebdea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EmbeddingDimension.BAAI_BGE_M3.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca8cd6b5-71ac-4d98-9ded-4747cae64ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16058/107190707.py:1: UserWarning: [EXPERIMENT] You're using an experimental module, which is subject to change in future.: BAAIEmbedding\n",
      "  baai_em = BAAIEmbedding()\n",
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 176726.29it/s]\n"
     ]
    }
   ],
   "source": [
    "baai_em = BAAIEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0aba0e50-3646-460b-9526-ddd760939e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vector = baai_em.run([\"test\", \"tost\"])\n",
    "test_vector.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89fddf17-ba37-442c-b200-98a7a6522b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_1 = [\"What is BGE M3?\", \"Defination of BM25\"]\n",
    "sentences_2 = [\"BGE M3 is an embedding model supporting dense retrieval, lexical matching and multi-vector interaction.\", \n",
    "               \"BM25 is a bag-of-words retrieval function that ranks a set of documents based on the query terms appearing in each document\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfd9f608-46dd-426e-b2cf-5df652d1531b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03412  , -0.047    , -0.0009174, ...,  0.04828  ,  0.00756  ,\n",
       "        -0.0296   ],\n",
       "       [-0.010376 , -0.04483  , -0.02428  , ..., -0.00822  ,  0.01502  ,\n",
       "         0.011086 ]], shape=(2, 1024), dtype=float16)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baai_em.run(sentences_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87da540-9127-4067-8b20-a6b35ba9d2aa",
   "metadata": {},
   "source": [
    "## CrossEncoder: cross-encoder/ms-marco-MiniLM-L6-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e650ce5-d3d2-47c1-964d-9590126c5dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from broai.experiments.cross_encoder import ReRanker\n",
    "from broai.interface import Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7ba15a8-b467-4abd-b80c-c2ef011e883b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16058/3697317191.py:1: UserWarning: [EXPERIMENT] You're using an experimental module, which is subject to change in future.: ReRanker\n",
      "  rr = ReRanker()\n"
     ]
    }
   ],
   "source": [
    "rr = ReRanker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72f2ec27-fd77-4ad2-bb7e-5601e07063a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"pandas is good\"\n",
    "contexts = [Context(context=con, metadata={\"source\":\"test\"}) for con in [\"pandas is goose\", \"pandas is good\", \"pandas is great\", \"pandas is goat\", \"pandas is gang\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c314e0b1-9ca8-4de9-8278-91527eb2e37c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Context(id='ae001360-79f5-4079-9c91-1b2753a57d49', context='pandas is good', metadata={'source': 'test'}, type='document', created_at='2025-04-29 22:28:55.115745'),\n",
       " Context(id='1c66b9fc-02c5-49af-9911-b691a006d0a5', context='pandas is great', metadata={'source': 'test'}, type='document', created_at='2025-04-29 22:28:55.115765'),\n",
       " Context(id='45507d99-b322-49a6-8577-e11992f52c07', context='pandas is goat', metadata={'source': 'test'}, type='document', created_at='2025-04-29 22:28:55.115782')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reranked_contexts, scores = rr.run(query, contexts, top_n=3)\n",
    "reranked_contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40fd3f40-47c5-4d62-bf55-5762bfdbf1c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8.630863189697266, 7.362998962402344, 0.6360796689987183]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ef4566-b0d1-41f4-a2f2-d621fd6869c5",
   "metadata": {},
   "source": [
    "## ExpBroAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f26fbda9-4aeb-40d8-8251-53d4d85aaf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from broai.experiments.bro_agent import BroAgent\n",
    "from broai.prompt_management.core import PromptGenerator\n",
    "from broai.prompt_management.interface import Persona, Instructions, Examples, Example\n",
    "from typing import List\n",
    "from broai.llm_management.ollama import BedrockOllamaChat\n",
    "bedrock_model = BedrockOllamaChat(model_name='us.meta.llama3-2-11b-instruct-v1:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f5a03fa-e8ec-4ec7-b148-766751b7fbe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jokes=[Joke(setup=\"Why don't scientists trust atoms?\", punchline='Because they make up everything'), Joke(setup=\"Why don't eggs tell jokes?\", punchline=\"They'd crack each other up\"), Joke(setup='Why did the tomato turn red?', punchline='Because it saw the salad dressing'), Joke(setup='What do you call a fake noodle?', punchline='An impasta'), Joke(setup='Why did the scarecrow win an award?', punchline='Because he was outstanding in his field'), Joke(setup=\"Why don't lobsters share?\", punchline=\"Because they're shellfish\"), Joke(setup=\"What do you call a can opener that doesn't work?\", punchline=\"A can't opener\"), Joke(setup='I told my wife she was drawing her eyebrows too high.', punchline='She looked surprised'), Joke(setup=\"Why don't some couples go to the gym?\", punchline=\"Because some relationships don't work out\"), Joke(setup='Why did the bicycle fall over?', punchline='Because it was two-tired'), Joke(setup='What do you call a bear with no socks on?', punchline='Barefoot'), Joke(setup='Why did the banana go to the doctor?', punchline=\"Because he wasn't peeling well\"), Joke(setup='Why did the baker go to the bank?', punchline='He needed dough'), Joke(setup='Why did the mushroom go to the party?', punchline='Because he was a fun-gi'), Joke(setup='Why did the cat join a band?', punchline='Because he wanted to be the purr-cussionist'), Joke(setup='What do you call a group of cows playing instruments?', punchline='A moo-sical band'), Joke(setup='Why did the computer go to the doctor?', punchline='It had a virus'), Joke(setup='Why did the kid bring a ladder to school?', punchline='He wanted to reach his full potential'), Joke(setup='What do you call a dog that does magic tricks?', punchline='A labracadabrador'), Joke(setup='Why did the orange stop in the middle of the road?', punchline='Because it ran out of juice')]\n",
      "CPU times: user 76.1 ms, sys: 20 ms, total: 96.1 ms\n",
      "Wall time: 5.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "class InputFormat(BaseModel):\n",
    "    message:str = Field(description=\"The user message\")\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    setup:str = Field(description=\"this is a setup for the joke\")\n",
    "    punchline:str = Field(description=\"this is a punchline of the joke\")\n",
    "\n",
    "class Jokes(BaseModel):\n",
    "    jokes:List[Joke]\n",
    "\n",
    "pg = PromptGenerator(\n",
    "    persona=Persona(name=\"Bro Andy\", description=\"You are the best bro who's cool and supportive.\"),\n",
    "    instructions=Instructions(\n",
    "        instructions=[\n",
    "            \"tell some jokes based on message\",\n",
    "        ],\n",
    "    ),\n",
    "    structured_output=Jokes,\n",
    "    examples=Examples(examples=[\n",
    "        Example(\n",
    "            setting=\"Funny Andy\",\n",
    "            input=InputFormat(message=\"Gimme three jokes\"),\n",
    "            output=Jokes(jokes=[\n",
    "                Joke(setup=\"the setup of the joke to build curiosity\", punchline=\"the punchline is to complete the joke\")\n",
    "            ]),\n",
    "        )\n",
    "    ]),\n",
    "    fallback=Jokes(jokes=[Joke(setup=\"error\", punchline=\"error\")])\n",
    ")\n",
    "\n",
    "bro = BroAgent(\n",
    "    prompt_generator=pg,\n",
    "    model=bedrock_model\n",
    ")\n",
    "\n",
    "response = bro.run(request=InputFormat(message=\"Tell me twenty jokes.\"))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b550e74-e20a-426c-878b-59b0e7bd6a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joke: 1\n",
      "setup: Why don't scientists trust atoms?\n",
      "punchline: Because they make up everything\n",
      "====================\n",
      "Joke: 2\n",
      "setup: Why don't eggs tell jokes?\n",
      "punchline: They'd crack each other up\n",
      "====================\n",
      "Joke: 3\n",
      "setup: Why did the tomato turn red?\n",
      "punchline: Because it saw the salad dressing\n",
      "====================\n",
      "Joke: 4\n",
      "setup: What do you call a fake noodle?\n",
      "punchline: An impasta\n",
      "====================\n",
      "Joke: 5\n",
      "setup: Why did the scarecrow win an award?\n",
      "punchline: Because he was outstanding in his field\n",
      "====================\n",
      "Joke: 6\n",
      "setup: Why don't lobsters share?\n",
      "punchline: Because they're shellfish\n",
      "====================\n",
      "Joke: 7\n",
      "setup: What do you call a can opener that doesn't work?\n",
      "punchline: A can't opener\n",
      "====================\n",
      "Joke: 8\n",
      "setup: I told my wife she was drawing her eyebrows too high.\n",
      "punchline: She looked surprised\n",
      "====================\n",
      "Joke: 9\n",
      "setup: Why don't some couples go to the gym?\n",
      "punchline: Because some relationships don't work out\n",
      "====================\n",
      "Joke: 10\n",
      "setup: Why did the bicycle fall over?\n",
      "punchline: Because it was two-tired\n",
      "====================\n",
      "Joke: 11\n",
      "setup: What do you call a bear with no socks on?\n",
      "punchline: Barefoot\n",
      "====================\n",
      "Joke: 12\n",
      "setup: Why did the banana go to the doctor?\n",
      "punchline: Because he wasn't peeling well\n",
      "====================\n",
      "Joke: 13\n",
      "setup: Why did the baker go to the bank?\n",
      "punchline: He needed dough\n",
      "====================\n",
      "Joke: 14\n",
      "setup: Why did the mushroom go to the party?\n",
      "punchline: Because he was a fun-gi\n",
      "====================\n",
      "Joke: 15\n",
      "setup: Why did the cat join a band?\n",
      "punchline: Because he wanted to be the purr-cussionist\n",
      "====================\n",
      "Joke: 16\n",
      "setup: What do you call a group of cows playing instruments?\n",
      "punchline: A moo-sical band\n",
      "====================\n",
      "Joke: 17\n",
      "setup: Why did the computer go to the doctor?\n",
      "punchline: It had a virus\n",
      "====================\n",
      "Joke: 18\n",
      "setup: Why did the kid bring a ladder to school?\n",
      "punchline: He wanted to reach his full potential\n",
      "====================\n",
      "Joke: 19\n",
      "setup: What do you call a dog that does magic tricks?\n",
      "punchline: A labracadabrador\n",
      "====================\n",
      "Joke: 20\n",
      "setup: Why did the orange stop in the middle of the road?\n",
      "punchline: Because it ran out of juice\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "for enum, j in enumerate(response.jokes):\n",
    "    print(\"Joke:\", enum+1)\n",
    "    print(\"setup:\", j.setup)\n",
    "    print(\"punchline:\", j.punchline)\n",
    "    print(\"=\"*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7955cca-2f32-4143-913b-18a7d6bf74af",
   "metadata": {},
   "source": [
    "## VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15c0f0eb-b058-4ba5-abbd-655d788d97c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/broai/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from broai.experiments.vector_store import DuckVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "309de215-9b6f-4580-98e7-5e7f69a7c2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19300/2813979473.py:4: UserWarning: [EXPERIMENT] You're using an experimental module, which is subject to change in future.: BAAIEmbedding\n",
      "  baai_em = BAAIEmbedding()\n",
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 182625.72it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from broai.interface import Context\n",
    "from broai.experiments.huggingface_embedding import BAAIEmbedding, EmbeddingDimension\n",
    "baai_em = BAAIEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c24bc6e4-499b-4c17-a3d4-d873f90e7121",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19300/4017906861.py:4: UserWarning: [EXPERIMENT] You're using an experimental module, which is subject to change in future.: ReRanker\n",
      "  rr = ReRanker()\n"
     ]
    }
   ],
   "source": [
    "from broai.experiments.cross_encoder import ReRanker\n",
    "from broai.interface import Context\n",
    "\n",
    "rr = ReRanker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f68389aa-9bd0-42a3-9cbf-b7a6a5895e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19300/1754148831.py:1: UserWarning: [EXPERIMENT] You're using an experimental module, which is subject to change in future.: DuckVectorStore\n",
      "  vector_store = DuckVectorStore(db_name=\"./duckmemory.db\", table=\"raw\", embedding=baai_em)\n",
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "vector_store = DuckVectorStore(db_name=\"./duckmemory.db\", table=\"raw\", embedding=baai_em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d597f2ed-4684-4131-ac72-f243ee4fb575",
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = [\n",
    "    Context(context=\"test's\", metadata={\"source\":\"source\", \"section\": \"section\", \"sequence\":0}),\n",
    "    Context(context=\"tost\", metadata={\"source\":\"source\", \"section\": \"section\", \"sequence\":1}),\n",
    "    Context(context=\"tast\", metadata={\"source\":\"source\", \"section\": \"section\", \"sequence\":2}),\n",
    "]\n",
    "vector_store.add_contexts(contexts=contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c43c92ce-ce4e-4d00-b8b0-18554b80e6e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>context</th>\n",
       "      <th>metadata</th>\n",
       "      <th>type</th>\n",
       "      <th>embedding</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79f8cc00-d469-4f11-b57a-329907bb7889</td>\n",
       "      <td>test's</td>\n",
       "      <td>{\"source\":\"source\",\"section\":\"section\",\"sequen...</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.015838623, 0.0026397705, -0.061553955, -0....</td>\n",
       "      <td>2025-05-05 00:02:12.436072</td>\n",
       "      <td>2025-05-05 00:02:12.436072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53235ade-9ea8-4fef-b7c6-2496e8f4a1af</td>\n",
       "      <td>tost</td>\n",
       "      <td>{\"source\":\"source\",\"section\":\"section\",\"sequen...</td>\n",
       "      <td>document</td>\n",
       "      <td>[0.03491211, 0.040252686, 0.010864258, 0.02061...</td>\n",
       "      <td>2025-05-05 00:02:12.436135</td>\n",
       "      <td>2025-05-05 00:02:12.436135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f7e7d21a-a2bc-45fd-8ad1-29bf0509e03c</td>\n",
       "      <td>tast</td>\n",
       "      <td>{\"source\":\"source\",\"section\":\"section\",\"sequen...</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.027191162, 0.010307312, 0.0028152466, -0.0...</td>\n",
       "      <td>2025-05-05 00:02:12.436158</td>\n",
       "      <td>2025-05-05 00:02:12.436158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id context  \\\n",
       "0  79f8cc00-d469-4f11-b57a-329907bb7889  test's   \n",
       "1  53235ade-9ea8-4fef-b7c6-2496e8f4a1af    tost   \n",
       "2  f7e7d21a-a2bc-45fd-8ad1-29bf0509e03c    tast   \n",
       "\n",
       "                                            metadata      type  \\\n",
       "0  {\"source\":\"source\",\"section\":\"section\",\"sequen...  document   \n",
       "1  {\"source\":\"source\",\"section\":\"section\",\"sequen...  document   \n",
       "2  {\"source\":\"source\",\"section\":\"section\",\"sequen...  document   \n",
       "\n",
       "                                           embedding  \\\n",
       "0  [-0.015838623, 0.0026397705, -0.061553955, -0....   \n",
       "1  [0.03491211, 0.040252686, 0.010864258, 0.02061...   \n",
       "2  [-0.027191162, 0.010307312, 0.0028152466, -0.0...   \n",
       "\n",
       "                  created_at                 updated_at  \n",
       "0 2025-05-05 00:02:12.436072 2025-05-05 00:02:12.436072  \n",
       "1 2025-05-05 00:02:12.436135 2025-05-05 00:02:12.436135  \n",
       "2 2025-05-05 00:02:12.436158 2025-05-05 00:02:12.436158  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = vector_store.read_all()\n",
    "records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a108d70d-667b-4271-bf9d-1a988b5632f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Context(id='f7e7d21a-a2bc-45fd-8ad1-29bf0509e03c', context='tast', metadata={'source': 'source', 'section': 'section', 'sequence': 2}, type='document', created_at=Timestamp('2025-05-05 00:02:12.436158')),\n",
       " Context(id='79f8cc00-d469-4f11-b57a-329907bb7889', context=\"test's\", metadata={'source': 'source', 'section': 'section', 'sequence': 0}, type='document', created_at=Timestamp('2025-05-05 00:02:12.436072'))]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = records['id'].tolist()\n",
    "\n",
    "vector_store.search_by_ids(ids=[ids[-1], ids[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a330cd23-bddd-4ec2-8d79-458a396a94e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>context</th>\n",
       "      <th>metadata</th>\n",
       "      <th>type</th>\n",
       "      <th>embedding</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2d0682f0-fb33-4c52-bc43-5cf5b0f5f0b3</td>\n",
       "      <td>tost</td>\n",
       "      <td>{\"source\":\"source\",\"section\":\"section\",\"sequen...</td>\n",
       "      <td>document</td>\n",
       "      <td>[0.03491211, 0.040252686, 0.010864258, 0.02061...</td>\n",
       "      <td>2025-04-29 22:29:06.138668</td>\n",
       "      <td>2025-04-29 22:29:06.138668</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37c792d9-bd93-4612-87fa-9819989cada5</td>\n",
       "      <td>tast</td>\n",
       "      <td>{\"source\":\"source\",\"section\":\"section\",\"sequen...</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.027191162, 0.010307312, 0.0028152466, -0.0...</td>\n",
       "      <td>2025-04-29 22:29:06.138704</td>\n",
       "      <td>2025-04-29 22:29:06.138704</td>\n",
       "      <td>0.635021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81531358-ac5c-47a7-8361-845772b636b4</td>\n",
       "      <td>test's</td>\n",
       "      <td>{\"source\":\"source\",\"section\":\"section\",\"sequen...</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.015838623, 0.0026397705, -0.061553955, -0....</td>\n",
       "      <td>2025-04-29 22:29:06.138540</td>\n",
       "      <td>2025-04-29 22:29:06.138540</td>\n",
       "      <td>0.601116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id context  \\\n",
       "0  2d0682f0-fb33-4c52-bc43-5cf5b0f5f0b3    tost   \n",
       "1  37c792d9-bd93-4612-87fa-9819989cada5    tast   \n",
       "2  81531358-ac5c-47a7-8361-845772b636b4  test's   \n",
       "\n",
       "                                            metadata      type  \\\n",
       "0  {\"source\":\"source\",\"section\":\"section\",\"sequen...  document   \n",
       "1  {\"source\":\"source\",\"section\":\"section\",\"sequen...  document   \n",
       "2  {\"source\":\"source\",\"section\":\"section\",\"sequen...  document   \n",
       "\n",
       "                                           embedding  \\\n",
       "0  [0.03491211, 0.040252686, 0.010864258, 0.02061...   \n",
       "1  [-0.027191162, 0.010307312, 0.0028152466, -0.0...   \n",
       "2  [-0.015838623, 0.0026397705, -0.061553955, -0....   \n",
       "\n",
       "                  created_at                 updated_at     score  \n",
       "0 2025-04-29 22:29:06.138668 2025-04-29 22:29:06.138668  1.000000  \n",
       "1 2025-04-29 22:29:06.138704 2025-04-29 22:29:06.138704  0.635021  \n",
       "2 2025-04-29 22:29:06.138540 2025-04-29 22:29:06.138540  0.601116  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = vector_store.vector_search(search_query=\"tost\", context=False)\n",
    "records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5ad8f260-4945-4c17-baaf-2ecc8fadee6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>context</th>\n",
       "      <th>metadata</th>\n",
       "      <th>type</th>\n",
       "      <th>embedding</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2d0682f0-fb33-4c52-bc43-5cf5b0f5f0b3</td>\n",
       "      <td>tost</td>\n",
       "      <td>{\"source\":\"source\",\"section\":\"section\",\"sequen...</td>\n",
       "      <td>document</td>\n",
       "      <td>[0.03491211, 0.040252686, 0.010864258, 0.02061...</td>\n",
       "      <td>2025-04-29 22:29:06.138668</td>\n",
       "      <td>2025-04-29 22:29:06.138668</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37c792d9-bd93-4612-87fa-9819989cada5</td>\n",
       "      <td>tast</td>\n",
       "      <td>{\"source\":\"source\",\"section\":\"section\",\"sequen...</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.027191162, 0.010307312, 0.0028152466, -0.0...</td>\n",
       "      <td>2025-04-29 22:29:06.138704</td>\n",
       "      <td>2025-04-29 22:29:06.138704</td>\n",
       "      <td>0.635021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81531358-ac5c-47a7-8361-845772b636b4</td>\n",
       "      <td>test's</td>\n",
       "      <td>{\"source\":\"source\",\"section\":\"section\",\"sequen...</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.015838623, 0.0026397705, -0.061553955, -0....</td>\n",
       "      <td>2025-04-29 22:29:06.138540</td>\n",
       "      <td>2025-04-29 22:29:06.138540</td>\n",
       "      <td>0.601116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id context  \\\n",
       "0  2d0682f0-fb33-4c52-bc43-5cf5b0f5f0b3    tost   \n",
       "1  37c792d9-bd93-4612-87fa-9819989cada5    tast   \n",
       "2  81531358-ac5c-47a7-8361-845772b636b4  test's   \n",
       "\n",
       "                                            metadata      type  \\\n",
       "0  {\"source\":\"source\",\"section\":\"section\",\"sequen...  document   \n",
       "1  {\"source\":\"source\",\"section\":\"section\",\"sequen...  document   \n",
       "2  {\"source\":\"source\",\"section\":\"section\",\"sequen...  document   \n",
       "\n",
       "                                           embedding  \\\n",
       "0  [0.03491211, 0.040252686, 0.010864258, 0.02061...   \n",
       "1  [-0.027191162, 0.010307312, 0.0028152466, -0.0...   \n",
       "2  [-0.015838623, 0.0026397705, -0.061553955, -0....   \n",
       "\n",
       "                  created_at                 updated_at     score  \n",
       "0 2025-04-29 22:29:06.138668 2025-04-29 22:29:06.138668  1.000000  \n",
       "1 2025-04-29 22:29:06.138704 2025-04-29 22:29:06.138704  0.635021  \n",
       "2 2025-04-29 22:29:06.138540 2025-04-29 22:29:06.138540  0.601116  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_metadata = {\"source\": \"source\"}\n",
    "records = vector_store.vector_search(search_query=\"tost\", filter_metadata=filter_metadata, context=False)\n",
    "records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ff455f58-781c-4827-89f9-4d224c0281bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Context(id='2d0682f0-fb33-4c52-bc43-5cf5b0f5f0b3', context='tost', metadata={'source': 'source', 'section': 'section', 'sequence': 1}, type='document', created_at=Timestamp('2025-04-29 22:29:06.138668')),\n",
       " Context(id='37c792d9-bd93-4612-87fa-9819989cada5', context='tast', metadata={'source': 'source', 'section': 'section', 'sequence': 2}, type='document', created_at=Timestamp('2025-04-29 22:29:06.138704')),\n",
       " Context(id='81531358-ac5c-47a7-8361-845772b636b4', context=\"test's\", metadata={'source': 'source', 'section': 'section', 'sequence': 0}, type='document', created_at=Timestamp('2025-04-29 22:29:06.138540'))]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_metadata = {\"source\": \"source\"}\n",
    "records = vector_store.vector_search(search_query=\"tost\", filter_metadata=filter_metadata, context=True)\n",
    "records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "46860923-87e5-4925-8935-4f1b4948d115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Context(id='2d0682f0-fb33-4c52-bc43-5cf5b0f5f0b3', context='tost', metadata={'source': 'source', 'section': 'section', 'sequence': 1}, type='document', created_at=Timestamp('2025-04-29 22:29:06.138668')),\n",
       " Context(id='37c792d9-bd93-4612-87fa-9819989cada5', context='tast', metadata={'source': 'source', 'section': 'section', 'sequence': 2}, type='document', created_at=Timestamp('2025-04-29 22:29:06.138704')),\n",
       " Context(id='81531358-ac5c-47a7-8361-845772b636b4', context=\"test's\", metadata={'source': 'source', 'section': 'section', 'sequence': 0}, type='document', created_at=Timestamp('2025-04-29 22:29:06.138540'))]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reranked_contexts, scores = rr.run(search_query=\"tost\", contexts=records)\n",
    "reranked_contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3a490d2f-eefb-45a0-8683-4ef4ed3ee3dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>context</th>\n",
       "      <th>metadata</th>\n",
       "      <th>type</th>\n",
       "      <th>embedding</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2d0682f0-fb33-4c52-bc43-5cf5b0f5f0b3</td>\n",
       "      <td>tost</td>\n",
       "      <td>{\"source\":\"source\",\"section\":\"section\",\"sequen...</td>\n",
       "      <td>document</td>\n",
       "      <td>[0.03491211, 0.040252686, 0.010864258, 0.02061...</td>\n",
       "      <td>2025-04-29 22:29:06.138668</td>\n",
       "      <td>2025-04-29 22:29:06.138668</td>\n",
       "      <td>0.425969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37c792d9-bd93-4612-87fa-9819989cada5</td>\n",
       "      <td>tast</td>\n",
       "      <td>{\"source\":\"source\",\"section\":\"section\",\"sequen...</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.027191162, 0.010307312, 0.0028152466, -0.0...</td>\n",
       "      <td>2025-04-29 22:29:06.138704</td>\n",
       "      <td>2025-04-29 22:29:06.138704</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81531358-ac5c-47a7-8361-845772b636b4</td>\n",
       "      <td>test's</td>\n",
       "      <td>{\"source\":\"source\",\"section\":\"section\",\"sequen...</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.015838623, 0.0026397705, -0.061553955, -0....</td>\n",
       "      <td>2025-04-29 22:29:06.138540</td>\n",
       "      <td>2025-04-29 22:29:06.138540</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id context  \\\n",
       "0  2d0682f0-fb33-4c52-bc43-5cf5b0f5f0b3    tost   \n",
       "1  37c792d9-bd93-4612-87fa-9819989cada5    tast   \n",
       "2  81531358-ac5c-47a7-8361-845772b636b4  test's   \n",
       "\n",
       "                                            metadata      type  \\\n",
       "0  {\"source\":\"source\",\"section\":\"section\",\"sequen...  document   \n",
       "1  {\"source\":\"source\",\"section\":\"section\",\"sequen...  document   \n",
       "2  {\"source\":\"source\",\"section\":\"section\",\"sequen...  document   \n",
       "\n",
       "                                           embedding  \\\n",
       "0  [0.03491211, 0.040252686, 0.010864258, 0.02061...   \n",
       "1  [-0.027191162, 0.010307312, 0.0028152466, -0.0...   \n",
       "2  [-0.015838623, 0.0026397705, -0.061553955, -0....   \n",
       "\n",
       "                  created_at                 updated_at     score  \n",
       "0 2025-04-29 22:29:06.138668 2025-04-29 22:29:06.138668  0.425969  \n",
       "1 2025-04-29 22:29:06.138704 2025-04-29 22:29:06.138704       NaN  \n",
       "2 2025-04-29 22:29:06.138540 2025-04-29 22:29:06.138540       NaN  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = vector_store.fulltext_search(search_query=\"tost\", context=False)\n",
    "records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "791f5043-6ef7-4c5c-a079-261a7ca7fec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Context(id='2d0682f0-fb33-4c52-bc43-5cf5b0f5f0b3', context='tost', metadata={'source': 'source', 'section': 'section', 'sequence': 1}, type='document', created_at=Timestamp('2025-04-29 22:29:06.138668'))]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = vector_store.fulltext_search(search_query=\"tost\", context=True)\n",
    "records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "54e75652-ed09-4fc8-86f5-b143164929e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Context(id='2d0682f0-fb33-4c52-bc43-5cf5b0f5f0b3', context='tost', metadata={'source': 'source', 'section': 'section', 'sequence': 1}, type='document', created_at=Timestamp('2025-04-29 22:29:06.138668')),\n",
       " Context(id='37c792d9-bd93-4612-87fa-9819989cada5', context='tast', metadata={'source': 'source', 'section': 'section', 'sequence': 2}, type='document', created_at=Timestamp('2025-04-29 22:29:06.138704')),\n",
       " Context(id='81531358-ac5c-47a7-8361-845772b636b4', context=\"test's\", metadata={'source': 'source', 'section': 'section', 'sequence': 0}, type='document', created_at=Timestamp('2025-04-29 22:29:06.138540'))]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = vector_store.search(search_query=\"tost\", context=True, search_method=\"vector\")\n",
    "records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8ba3a03a-da99-4c01-bb43-d8d3bb57d2e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Context(id='2d0682f0-fb33-4c52-bc43-5cf5b0f5f0b3', context='tost', metadata={'source': 'source', 'section': 'section', 'sequence': 1}, type='document', created_at=Timestamp('2025-04-29 22:29:06.138668'))]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = vector_store.search(search_query=\"tost\", context=True, search_method=\"fulltext\")\n",
    "records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "db751f82-6e4b-45cb-89c5-ce427e2bbbcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Context(id='2d0682f0-fb33-4c52-bc43-5cf5b0f5f0b3', context='tost', metadata={'source': 'source', 'section': 'section', 'sequence': 1}, type='document', created_at=Timestamp('2025-04-29 22:29:06.138668')),\n",
       " Context(id='37c792d9-bd93-4612-87fa-9819989cada5', context='tast', metadata={'source': 'source', 'section': 'section', 'sequence': 2}, type='document', created_at=Timestamp('2025-04-29 22:29:06.138704')),\n",
       " Context(id='81531358-ac5c-47a7-8361-845772b636b4', context=\"test's\", metadata={'source': 'source', 'section': 'section', 'sequence': 0}, type='document', created_at=Timestamp('2025-04-29 22:29:06.138540'))]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = vector_store.search(search_query=\"tost\", search_method=\"hybrid\")\n",
    "records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8095c358-f6fa-44bc-9a53-1438fe1e08d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.delete_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "298009f3-47a8-42d9-a497-187eb6d6f132",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.drop_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cedabadb-b43b-47cf-a3e3-585a6f81d7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you want to remove database, use confirm 'remove ./duckmemory.db'\n"
     ]
    }
   ],
   "source": [
    "vector_store.remove_database(confirm=\"remove database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0f6423-9486-4cbc-a18a-c8182b1a198c",
   "metadata": {},
   "source": [
    "### CRUD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "07b174bd-1833-4a4a-9865-39aaa5430839",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16058/3318005302.py:5: UserWarning: [EXPERIMENT] You're using an experimental module, which is subject to change in future.: BAAIEmbedding\n",
      "  baai_em = BAAIEmbedding()\n",
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 223895.23it/s]\n"
     ]
    }
   ],
   "source": [
    "from broai.experiments.vector_store import DuckVectorStore\n",
    "import json\n",
    "from broai.interface import Context\n",
    "from broai.experiments.huggingface_embedding import BAAIEmbedding, EmbeddingDimension\n",
    "baai_em = BAAIEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9431bea0-9297-4407-8e0e-c6a97a7ab91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16058/3005562315.py:1: UserWarning: [EXPERIMENT] You're using an experimental module, which is subject to change in future.: DuckVectorStore\n",
      "  test_vs = DuckVectorStore(db_name=\"./test.db\", table=\"test_vs\", embedding=baai_em)\n",
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "test_vs = DuckVectorStore(db_name=\"./test.db\", table=\"test_vs\", embedding=baai_em)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcdb03b-f8a6-4db7-b0c9-ec9be816a384",
   "metadata": {},
   "source": [
    "#### Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "36b1e724-6333-45bc-80ab-972af1a54516",
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = [\n",
    "    Context(id=f\"{i}\", context=f\"test{i}\", metadata={\"source\":f\"source{i}\", \"sequence\":i}) for i in range(5)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "581d0e7f-b046-481f-9f07-c06f8932d674",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vs.add_contexts(contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095c2316-36bf-4c45-9dda-235e4deaa3f7",
   "metadata": {},
   "source": [
    "#### Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1fb8ad67-49d3-46cc-baa2-549943b0d8a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>context</th>\n",
       "      <th>metadata</th>\n",
       "      <th>type</th>\n",
       "      <th>embedding</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>test0</td>\n",
       "      <td>{\"source\":\"source0\",\"sequence\":0}</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.005302429, 0.035308838, -0.023620605, -0.0...</td>\n",
       "      <td>2025-04-29 22:29:11.045269</td>\n",
       "      <td>2025-04-29 22:29:11.045269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>test1</td>\n",
       "      <td>{\"source\":\"source1\",\"sequence\":1}</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.013961792, 0.053588867, -0.037475586, -0.0...</td>\n",
       "      <td>2025-04-29 22:29:11.045300</td>\n",
       "      <td>2025-04-29 22:29:11.045300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>test2</td>\n",
       "      <td>{\"source\":\"source2\",\"sequence\":2}</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.02861023, 0.030181885, -0.023010254, -0.00...</td>\n",
       "      <td>2025-04-29 22:29:11.045309</td>\n",
       "      <td>2025-04-29 22:29:11.045309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>test3</td>\n",
       "      <td>{\"source\":\"source3\",\"sequence\":3}</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.012084961, 0.018630981, -0.040893555, -0.0...</td>\n",
       "      <td>2025-04-29 22:29:11.045316</td>\n",
       "      <td>2025-04-29 22:29:11.045316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>test4</td>\n",
       "      <td>{\"source\":\"source4\",\"sequence\":4}</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.011680603, 0.06719971, -0.017745972, -0.00...</td>\n",
       "      <td>2025-04-29 22:29:11.045322</td>\n",
       "      <td>2025-04-29 22:29:11.045322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id context                           metadata      type  \\\n",
       "0  0   test0  {\"source\":\"source0\",\"sequence\":0}  document   \n",
       "1  1   test1  {\"source\":\"source1\",\"sequence\":1}  document   \n",
       "2  2   test2  {\"source\":\"source2\",\"sequence\":2}  document   \n",
       "3  3   test3  {\"source\":\"source3\",\"sequence\":3}  document   \n",
       "4  4   test4  {\"source\":\"source4\",\"sequence\":4}  document   \n",
       "\n",
       "                                           embedding  \\\n",
       "0  [-0.005302429, 0.035308838, -0.023620605, -0.0...   \n",
       "1  [-0.013961792, 0.053588867, -0.037475586, -0.0...   \n",
       "2  [-0.02861023, 0.030181885, -0.023010254, -0.00...   \n",
       "3  [-0.012084961, 0.018630981, -0.040893555, -0.0...   \n",
       "4  [-0.011680603, 0.06719971, -0.017745972, -0.00...   \n",
       "\n",
       "                  created_at                 updated_at  \n",
       "0 2025-04-29 22:29:11.045269 2025-04-29 22:29:11.045269  \n",
       "1 2025-04-29 22:29:11.045300 2025-04-29 22:29:11.045300  \n",
       "2 2025-04-29 22:29:11.045309 2025-04-29 22:29:11.045309  \n",
       "3 2025-04-29 22:29:11.045316 2025-04-29 22:29:11.045316  \n",
       "4 2025-04-29 22:29:11.045322 2025-04-29 22:29:11.045322  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vs.read_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1d0d1a61-5eee-4350-9a48-a72c5138ce34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>context</th>\n",
       "      <th>metadata</th>\n",
       "      <th>type</th>\n",
       "      <th>embedding</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>test0</td>\n",
       "      <td>{\"source\":\"source0\",\"sequence\":0}</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.005302429, 0.035308838, -0.023620605, -0.0...</td>\n",
       "      <td>2025-04-29 22:29:11.045269</td>\n",
       "      <td>2025-04-29 22:29:11.045269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>test1</td>\n",
       "      <td>{\"source\":\"source1\",\"sequence\":1}</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.013961792, 0.053588867, -0.037475586, -0.0...</td>\n",
       "      <td>2025-04-29 22:29:11.045300</td>\n",
       "      <td>2025-04-29 22:29:11.045300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>test2</td>\n",
       "      <td>{\"source\":\"source2\",\"sequence\":2}</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.02861023, 0.030181885, -0.023010254, -0.00...</td>\n",
       "      <td>2025-04-29 22:29:11.045309</td>\n",
       "      <td>2025-04-29 22:29:11.045309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>test3</td>\n",
       "      <td>{\"source\":\"source3\",\"sequence\":3}</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.012084961, 0.018630981, -0.040893555, -0.0...</td>\n",
       "      <td>2025-04-29 22:29:11.045316</td>\n",
       "      <td>2025-04-29 22:29:11.045316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id context                           metadata      type  \\\n",
       "0  0   test0  {\"source\":\"source0\",\"sequence\":0}  document   \n",
       "1  1   test1  {\"source\":\"source1\",\"sequence\":1}  document   \n",
       "2  2   test2  {\"source\":\"source2\",\"sequence\":2}  document   \n",
       "3  3   test3  {\"source\":\"source3\",\"sequence\":3}  document   \n",
       "\n",
       "                                           embedding  \\\n",
       "0  [-0.005302429, 0.035308838, -0.023620605, -0.0...   \n",
       "1  [-0.013961792, 0.053588867, -0.037475586, -0.0...   \n",
       "2  [-0.02861023, 0.030181885, -0.023010254, -0.00...   \n",
       "3  [-0.012084961, 0.018630981, -0.040893555, -0.0...   \n",
       "\n",
       "                  created_at                 updated_at  \n",
       "0 2025-04-29 22:29:11.045269 2025-04-29 22:29:11.045269  \n",
       "1 2025-04-29 22:29:11.045300 2025-04-29 22:29:11.045300  \n",
       "2 2025-04-29 22:29:11.045309 2025-04-29 22:29:11.045309  \n",
       "3 2025-04-29 22:29:11.045316 2025-04-29 22:29:11.045316  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vs.read_by_ids(ids=[\"0\", \"1\", \"2\", \"3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0a5f2697-e077-4b66-b208-86539b467867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>context</th>\n",
       "      <th>metadata</th>\n",
       "      <th>type</th>\n",
       "      <th>embedding</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>test3</td>\n",
       "      <td>{\"source\":\"source3\",\"sequence\":3}</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.012084961, 0.018630981, -0.040893555, -0.0...</td>\n",
       "      <td>2025-04-29 22:29:11.045316</td>\n",
       "      <td>2025-04-29 22:29:11.045316</td>\n",
       "      <td>0.037789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>test1</td>\n",
       "      <td>{\"source\":\"source1\",\"sequence\":1}</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.013961792, 0.053588867, -0.037475586, -0.0...</td>\n",
       "      <td>2025-04-29 22:29:11.045300</td>\n",
       "      <td>2025-04-29 22:29:11.045300</td>\n",
       "      <td>0.037789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>test4</td>\n",
       "      <td>{\"source\":\"source4\",\"sequence\":4}</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.011680603, 0.06719971, -0.017745972, -0.00...</td>\n",
       "      <td>2025-04-29 22:29:11.045322</td>\n",
       "      <td>2025-04-29 22:29:11.045322</td>\n",
       "      <td>0.037789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>test2</td>\n",
       "      <td>{\"source\":\"source2\",\"sequence\":2}</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.02861023, 0.030181885, -0.023010254, -0.00...</td>\n",
       "      <td>2025-04-29 22:29:11.045309</td>\n",
       "      <td>2025-04-29 22:29:11.045309</td>\n",
       "      <td>0.037789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>test0</td>\n",
       "      <td>{\"source\":\"source0\",\"sequence\":0}</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.005302429, 0.035308838, -0.023620605, -0.0...</td>\n",
       "      <td>2025-04-29 22:29:11.045269</td>\n",
       "      <td>2025-04-29 22:29:11.045269</td>\n",
       "      <td>0.037789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id context                           metadata      type  \\\n",
       "0  3   test3  {\"source\":\"source3\",\"sequence\":3}  document   \n",
       "1  1   test1  {\"source\":\"source1\",\"sequence\":1}  document   \n",
       "2  4   test4  {\"source\":\"source4\",\"sequence\":4}  document   \n",
       "3  2   test2  {\"source\":\"source2\",\"sequence\":2}  document   \n",
       "4  0   test0  {\"source\":\"source0\",\"sequence\":0}  document   \n",
       "\n",
       "                                           embedding  \\\n",
       "0  [-0.012084961, 0.018630981, -0.040893555, -0.0...   \n",
       "1  [-0.013961792, 0.053588867, -0.037475586, -0.0...   \n",
       "2  [-0.011680603, 0.06719971, -0.017745972, -0.00...   \n",
       "3  [-0.02861023, 0.030181885, -0.023010254, -0.00...   \n",
       "4  [-0.005302429, 0.035308838, -0.023620605, -0.0...   \n",
       "\n",
       "                  created_at                 updated_at     score  \n",
       "0 2025-04-29 22:29:11.045316 2025-04-29 22:29:11.045316  0.037789  \n",
       "1 2025-04-29 22:29:11.045300 2025-04-29 22:29:11.045300  0.037789  \n",
       "2 2025-04-29 22:29:11.045322 2025-04-29 22:29:11.045322  0.037789  \n",
       "3 2025-04-29 22:29:11.045309 2025-04-29 22:29:11.045309  0.037789  \n",
       "4 2025-04-29 22:29:11.045269 2025-04-29 22:29:11.045269  0.037789  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vs.fulltext_search(search_query=\"test4\", context=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "95bb74f9-3d73-47d6-a412-63497da88482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>context</th>\n",
       "      <th>metadata</th>\n",
       "      <th>type</th>\n",
       "      <th>embedding</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>test4</td>\n",
       "      <td>{\"source\":\"source4\",\"sequence\":4}</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.011680603, 0.06719971, -0.017745972, -0.00...</td>\n",
       "      <td>2025-04-29 22:29:11.045322</td>\n",
       "      <td>2025-04-29 22:29:11.045322</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id context                           metadata      type  \\\n",
       "0  4   test4  {\"source\":\"source4\",\"sequence\":4}  document   \n",
       "\n",
       "                                           embedding  \\\n",
       "0  [-0.011680603, 0.06719971, -0.017745972, -0.00...   \n",
       "\n",
       "                  created_at                 updated_at     score  \n",
       "0 2025-04-29 22:29:11.045322 2025-04-29 22:29:11.045322  0.999999  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vs.vector_search(search_query=\"test4\", filter_metadata={\"sequence\":4}, context=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "84177f26-061c-4d41-ad75-805a6b11ec59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Context(id='0', context='test0', metadata={'source': 'source0', 'sequence': 0}, type='document', created_at=Timestamp('2025-04-29 22:29:11.045269'))]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vs.search(search_query=\"test4\", filter_metadata={\"source\":\"source0\"}, search_method=\"vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3a12dab1-052d-426e-ac47-f63208945209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Context(id='0', context='test0', metadata={'source': 'source0', 'sequence': 0}, type='document', created_at=Timestamp('2025-04-29 22:29:11.045269'))]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vs.search(search_query=\"test4\", filter_metadata={\"source\":\"source0\"}, search_method=\"fulltext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d8726360-14f9-4027-a018-0b9fdb73e7c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Context(id='0', context='test0', metadata={'source': 'source0', 'sequence': 0}, type='document', created_at=Timestamp('2025-04-29 22:29:11.045269'))]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vs.search(search_query=\"test4\", filter_metadata={\"source\":\"source0\"}, search_method=\"hybrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7472ba7-fb42-4700-aeed-c5c869014421",
   "metadata": {},
   "source": [
    "#### Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0bdca3be-444c-48a3-8400-09e75f7339a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>context</th>\n",
       "      <th>metadata</th>\n",
       "      <th>type</th>\n",
       "      <th>embedding</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>updated_test0</td>\n",
       "      <td>{\"source\":\"updated_source0\"}</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.005302429, 0.035308838, -0.023620605, -0.0...</td>\n",
       "      <td>2025-04-29 22:29:11.045269</td>\n",
       "      <td>2025-04-29 22:29:12.024237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>test1</td>\n",
       "      <td>{\"source\":\"source1\",\"sequence\":1}</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.013961792, 0.053588867, -0.037475586, -0.0...</td>\n",
       "      <td>2025-04-29 22:29:11.045300</td>\n",
       "      <td>2025-04-29 22:29:11.045300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>test2</td>\n",
       "      <td>{\"source\":\"source2\",\"sequence\":2}</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.02861023, 0.030181885, -0.023010254, -0.00...</td>\n",
       "      <td>2025-04-29 22:29:11.045309</td>\n",
       "      <td>2025-04-29 22:29:11.045309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>test3</td>\n",
       "      <td>{\"source\":\"source3\",\"sequence\":3}</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.012084961, 0.018630981, -0.040893555, -0.0...</td>\n",
       "      <td>2025-04-29 22:29:11.045316</td>\n",
       "      <td>2025-04-29 22:29:11.045316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>test4</td>\n",
       "      <td>{\"source\":\"source4\",\"sequence\":4}</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.011680603, 0.06719971, -0.017745972, -0.00...</td>\n",
       "      <td>2025-04-29 22:29:11.045322</td>\n",
       "      <td>2025-04-29 22:29:11.045322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id        context                           metadata      type  \\\n",
       "0  0  updated_test0       {\"source\":\"updated_source0\"}  document   \n",
       "1  1          test1  {\"source\":\"source1\",\"sequence\":1}  document   \n",
       "2  2          test2  {\"source\":\"source2\",\"sequence\":2}  document   \n",
       "3  3          test3  {\"source\":\"source3\",\"sequence\":3}  document   \n",
       "4  4          test4  {\"source\":\"source4\",\"sequence\":4}  document   \n",
       "\n",
       "                                           embedding  \\\n",
       "0  [-0.005302429, 0.035308838, -0.023620605, -0.0...   \n",
       "1  [-0.013961792, 0.053588867, -0.037475586, -0.0...   \n",
       "2  [-0.02861023, 0.030181885, -0.023010254, -0.00...   \n",
       "3  [-0.012084961, 0.018630981, -0.040893555, -0.0...   \n",
       "4  [-0.011680603, 0.06719971, -0.017745972, -0.00...   \n",
       "\n",
       "                  created_at                 updated_at  \n",
       "0 2025-04-29 22:29:11.045269 2025-04-29 22:29:12.024237  \n",
       "1 2025-04-29 22:29:11.045300 2025-04-29 22:29:11.045300  \n",
       "2 2025-04-29 22:29:11.045309 2025-04-29 22:29:11.045309  \n",
       "3 2025-04-29 22:29:11.045316 2025-04-29 22:29:11.045316  \n",
       "4 2025-04-29 22:29:11.045322 2025-04-29 22:29:11.045322  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contexts = [Context(id=\"0\", context=\"updated_test0\", metadata={\"source\": \"updated_source0\"})]\n",
    "test_vs.update_contexts(contexts)\n",
    "test_vs.read_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8ebd3e-0ade-42c8-bf3c-282e8003fc2b",
   "metadata": {},
   "source": [
    "#### Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "750cda11-738b-4a9c-af4e-90c0b12ae569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Context(id='1', context='test1', metadata={'source': 'source1', 'sequence': 1}, type='document', created_at=Timestamp('2025-04-29 22:29:11.045300'))]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = test_vs.vector_search(search_query=\"test1\", filter_metadata={\"source\":\"source1\"})\n",
    "records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4bcd9a84-aad1-4951-b1ac-c8120f1c9c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>context</th>\n",
       "      <th>metadata</th>\n",
       "      <th>type</th>\n",
       "      <th>embedding</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>updated_test0</td>\n",
       "      <td>{\"source\":\"updated_source0\"}</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.005302429, 0.035308838, -0.023620605, -0.0...</td>\n",
       "      <td>2025-04-29 22:29:11.045269</td>\n",
       "      <td>2025-04-29 22:29:12.024237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>test2</td>\n",
       "      <td>{\"source\":\"source2\",\"sequence\":2}</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.02861023, 0.030181885, -0.023010254, -0.00...</td>\n",
       "      <td>2025-04-29 22:29:11.045309</td>\n",
       "      <td>2025-04-29 22:29:11.045309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>test3</td>\n",
       "      <td>{\"source\":\"source3\",\"sequence\":3}</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.012084961, 0.018630981, -0.040893555, -0.0...</td>\n",
       "      <td>2025-04-29 22:29:11.045316</td>\n",
       "      <td>2025-04-29 22:29:11.045316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>test4</td>\n",
       "      <td>{\"source\":\"source4\",\"sequence\":4}</td>\n",
       "      <td>document</td>\n",
       "      <td>[-0.011680603, 0.06719971, -0.017745972, -0.00...</td>\n",
       "      <td>2025-04-29 22:29:11.045322</td>\n",
       "      <td>2025-04-29 22:29:11.045322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id        context                           metadata      type  \\\n",
       "0  0  updated_test0       {\"source\":\"updated_source0\"}  document   \n",
       "1  2          test2  {\"source\":\"source2\",\"sequence\":2}  document   \n",
       "2  3          test3  {\"source\":\"source3\",\"sequence\":3}  document   \n",
       "3  4          test4  {\"source\":\"source4\",\"sequence\":4}  document   \n",
       "\n",
       "                                           embedding  \\\n",
       "0  [-0.005302429, 0.035308838, -0.023620605, -0.0...   \n",
       "1  [-0.02861023, 0.030181885, -0.023010254, -0.00...   \n",
       "2  [-0.012084961, 0.018630981, -0.040893555, -0.0...   \n",
       "3  [-0.011680603, 0.06719971, -0.017745972, -0.00...   \n",
       "\n",
       "                  created_at                 updated_at  \n",
       "0 2025-04-29 22:29:11.045269 2025-04-29 22:29:12.024237  \n",
       "1 2025-04-29 22:29:11.045309 2025-04-29 22:29:11.045309  \n",
       "2 2025-04-29 22:29:11.045316 2025-04-29 22:29:11.045316  \n",
       "3 2025-04-29 22:29:11.045322 2025-04-29 22:29:11.045322  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vs.delete_contexts(records)\n",
    "test_vs.read_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c1695b82-82ee-4a3f-be9f-7b46929b2ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vs.remove_database(confirm=f\"remove {test_vs.db_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f7c38e-def5-424b-8aa1-a08d936e51b7",
   "metadata": {},
   "source": [
    "## VectorStore: Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1259ae3-2070-42fd-9a5a-4fe53187318a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/broai/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/tmp/ipykernel_27567/1844728088.py:5: UserWarning: [EXPERIMENT] You're using an experimental module, which is subject to change in future.: BAAIEmbedding\n",
      "  baai_em = BAAIEmbedding()\n",
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 163840.00it/s]\n"
     ]
    }
   ],
   "source": [
    "from broai.experiments.vector_store import DuckVectorStore, filter_whitelist_query\n",
    "import json\n",
    "from broai.interface import Context\n",
    "from broai.experiments.huggingface_embedding import BAAIEmbedding, EmbeddingDimension\n",
    "baai_em = BAAIEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d0f68ff-a401-4639-9765-79e0ba35385a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27567/584304531.py:1: UserWarning: [EXPERIMENT] You're using an experimental module, which is subject to change in future.: DuckVectorStore\n",
      "  test_vs = DuckVectorStore(db_name=\"test_filter.db\", table=\"raw\", embedding=baai_em)\n"
     ]
    }
   ],
   "source": [
    "test_vs = DuckVectorStore(db_name=\"test_filter.db\", table=\"raw\", embedding=baai_em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18cbdb0b-036f-4f24-b46b-58b3e3ac2bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_whitelist = [\"medium.com\", \"geeksforgeeks.org\", \"towardsdatascience.com\"]\n",
    "\n",
    "whitelist = [\n",
    "    f\"www.{wl}/abc\"\n",
    "    for wl in default_whitelist\n",
    "]\n",
    "contexts = [\n",
    "    Context(context=text, metadata={\"source\": text})\n",
    "    for text in whitelist\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81d9d108-5a41-438f-9daa-d5c00a875b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vs.add_contexts(contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b8634f1-c81a-4714-92c9-26708ba581d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WHERE (metadata ->> 'source' LIKE '%medium.com%') OR (metadata ->> 'source' LIKE '%geeksforgeeks.org%') OR (metadata ->> 'source' LIKE '%towardsdatascience.com%') \n"
     ]
    }
   ],
   "source": [
    "print(filter_whitelist_query(default_whitelist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52515307-c266-4192-a708-23d9f46683f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Context(id='37f6c588-d85b-41ea-a3ec-e25dcfe30389', context='www.medium.com/abc', metadata={'source': 'www.medium.com/abc'}, type='document', created_at=Timestamp('2025-05-12 14:42:40.834473')),\n",
       " Context(id='f76cf910-74b8-4197-8b7b-601182c066b9', context='www.geeksforgeeks.org/abc', metadata={'source': 'www.geeksforgeeks.org/abc'}, type='document', created_at=Timestamp('2025-05-12 14:42:40.834526')),\n",
       " Context(id='c7c3aef8-2751-40f8-968b-e9357c95f09a', context='www.towardsdatascience.com/abc', metadata={'source': 'www.towardsdatascience.com/abc'}, type='document', created_at=Timestamp('2025-05-12 14:42:40.834546'))]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vs.search(search_query=\"medium\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e826637b-1475-412c-a116-bd983612e0c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Context(id='d1f72c34-b5ad-4c1d-a2e7-a0404f08b0da', context='www.medium.com/abc', metadata={'source': 'www.medium.com/abc'}, type='document', created_at=Timestamp('2025-05-12 16:41:10.873363'))]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vs.search(search_query=\"medium\", filter_metadata=filter_whitelist_query([\"medium.com\"]), search_method=\"hybrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1cac601-c3c7-4c42-83a1-4ab522519694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Context(id='d1f72c34-b5ad-4c1d-a2e7-a0404f08b0da', context='www.medium.com/abc', metadata={'source': 'www.medium.com/abc'}, type='document', created_at=Timestamp('2025-05-12 16:41:10.873363'))]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vs.vector_search(search_query=\"medium\", filter_metadata=filter_whitelist_query([\"medium.com\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "065abb30-8078-4d12-8376-87ef25b31dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Context(id='dcffed40-56b5-4a5e-9cb8-e3875c81b90f', context='www.geeksforgeeks.org/abc', metadata={'source': 'www.geeksforgeeks.org/abc'}, type='document', created_at=Timestamp('2025-05-12 16:41:10.873566'))]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vs.vector_search(search_query=\"medium\", filter_metadata=filter_whitelist_query([\"geeksforgeeks.org\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1485246c-4158-437c-95c5-ac77c22d4753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Context(id='33e17643-bea2-4b29-91da-a394345b6ca2', context='www.towardsdatascience.com/abc', metadata={'source': 'www.towardsdatascience.com/abc'}, type='document', created_at=Timestamp('2025-05-12 16:41:10.873689'))]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vs.vector_search(search_query=\"medium\", filter_metadata=filter_whitelist_query([\"towardsdatascience.com\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "23515bd4-c1dc-4367-a7d0-ab818401044a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Context(id='d1f72c34-b5ad-4c1d-a2e7-a0404f08b0da', context='www.medium.com/abc', metadata={'source': 'www.medium.com/abc'}, type='document', created_at=Timestamp('2025-05-12 16:41:10.873363')),\n",
       " Context(id='dcffed40-56b5-4a5e-9cb8-e3875c81b90f', context='www.geeksforgeeks.org/abc', metadata={'source': 'www.geeksforgeeks.org/abc'}, type='document', created_at=Timestamp('2025-05-12 16:41:10.873566'))]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vs.vector_search(search_query=\"medium\", filter_metadata=filter_whitelist_query([\"medium.com\", \"geeksforgeeks.org\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "086338d3-b37c-4b5f-80d6-751122a5d885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Context(id='d1f72c34-b5ad-4c1d-a2e7-a0404f08b0da', context='www.medium.com/abc', metadata={'source': 'www.medium.com/abc'}, type='document', created_at=Timestamp('2025-05-12 16:41:10.873363')),\n",
       " Context(id='dcffed40-56b5-4a5e-9cb8-e3875c81b90f', context='www.geeksforgeeks.org/abc', metadata={'source': 'www.geeksforgeeks.org/abc'}, type='document', created_at=Timestamp('2025-05-12 16:41:10.873566')),\n",
       " Context(id='33e17643-bea2-4b29-91da-a394345b6ca2', context='www.towardsdatascience.com/abc', metadata={'source': 'www.towardsdatascience.com/abc'}, type='document', created_at=Timestamp('2025-05-12 16:41:10.873689'))]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vs.vector_search(search_query=\"medium\", filter_metadata=filter_whitelist_query(default_whitelist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3c2e4818-731e-48b7-9faf-90c0857dfe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vs.remove_database(confirm='remove test_filter.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07811527-fc0b-4140-847f-857abaa89e68",
   "metadata": {},
   "source": [
    "# Scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30c1426b-07cd-44f0-bb58-df16d7151df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from broai.experiments.web_scraping import scrape_by_jina_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84ecf747-2f33-4bd3-922d-f42297d50380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Getting Started: Installation | Next.js\n",
      "\n",
      "URL Source: https://nextjs.org/docs/app/getting-started/installation\n",
      "\n",
      "Markdown Content:\n",
      "Getting Started: Installation | Next.js\n",
      "===============\n",
      " \n",
      "\n",
      "[Skip to content](https://nextjs.org/docs/app/getting-started/installation#geist-skip-nav)\n",
      "\n",
      "[](https://vercel.com/home?utm_source=next-site&utm_medium=banner&utm_campaign=docs_app_getting-started_installation \"Go to Vercel homepage\")\n",
      "\n",
      "[![Image 5: Next.js uwu logo by SAWARATSUKI](https://nextjs.org/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fv1714730590%2Ffront%2Fnextjs%2Fuwu%2Fnext-uwu-logo.png&w=128&q=75)](https://nextjs.org/?uwu=true \"Go to the homepage\")\n",
      "\n",
      "[](https://nextjs.org/ \"Go to the homepage\")\n",
      "\n",
      "Search documentation...CtrlKSearch...⌘K\n",
      "\n",
      "[](https://vercel.com/home?utm_source=next-site&utm_medium=banner&utm_campaign=docs_app_getting-started_installation \"Go to Vercel homepage\")\n",
      "\n",
      "[![Image 6: Next.js uwu logo by SAWARATSUKI](https://nextjs.org/_next/image?url=https%3A%\n"
     ]
    }
   ],
   "source": [
    "text = scrape_by_jina_ai(url=\"https://nextjs.org/docs/app/getting-started/installation\")\n",
    "print(text[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064f1a33-6a27-4702-870e-fcc17f74d0fc",
   "metadata": {},
   "source": [
    "# clean_up_markdown_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ea53afb-db46-494d-a251-3d516116c96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from broai.experiments.cleanup_markdown import clean_up_markdown_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec9c1488-2e8a-4dae-8fe7-f963d721b675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Getting Started: Installation | Next.js\n",
      "\n",
      "URL Source: https://nextjs.org/docs/app/getting-started/installation\n",
      "\n",
      "Markdown Content:\n",
      "Getting Started: Installation | Next.js\n",
      "===============\n",
      " \n",
      "\n",
      "Skip to content\n",
      "\n",
      "\n",
      "\n",
      "![Image 5: Next.js uwu logo by SAWARATSUKI](https://nextjs.org/?uwu=true \"Go to the homepage\")\n",
      "\n",
      "\n",
      "\n",
      "Search documentation...CtrlKSearch...⌘K\n",
      "\n",
      "\n",
      "\n",
      "![Image 6: Next.js uwu logo by SAWARATSUKI](https://nextjs.org/?uwu=true \"Go to the homepage\")\n",
      "\n",
      "\n",
      "\n",
      "ShowcaseDocsBlogTemplatesEnterprise\n",
      "\n",
      "Search documentation...CtrlKSearch...⌘KFeedbackLearn\n",
      "\n",
      "Menu\n",
      "\n",
      "Using App Router\n",
      "\n",
      "Features available in /app\n",
      "\n",
      "Using Latest Version\n",
      "\n",
      "15.3.1\n",
      "\n",
      "*   Getting Started\n",
      "    \n",
      "    *   Installation\n",
      "    *   Project Structure\n",
      "    *   Layouts and Pages\n",
      "    *   Images and Fonts\n",
      "    *   CSS\n",
      "    *   Fetching Data\n",
      "    *   Updating Data\n",
      "    *   Error Handling\n",
      "    *   Metadata and OG images\n",
      "    *   Deploying\n",
      "    *   Upgrading\n",
      "    \n",
      "\n",
      "*   Guides\n",
      "    \n",
      "    *   Analytics\n",
      "    *   Authentication\n",
      "    *   CI Build Caching\n",
      "    *   Content S\n"
     ]
    }
   ],
   "source": [
    "cleaned_text = clean_up_markdown_link(text)\n",
    "print(cleaned_text[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fba137c-3120-485c-8435-12e8d21ad2da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "broai",
   "language": "python",
   "name": "broai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
